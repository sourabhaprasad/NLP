{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d67d9522",
   "metadata": {},
   "source": [
    "## **PROGRAM 4 â€” Naive Bayes Text Classification**\n",
    "\n",
    "Demonstrates the use of a **Naive Bayes classifier** with:\n",
    "\n",
    "- Training data labeled as _comedy_ or _action_\n",
    "- **Add-one (Laplace) smoothing**\n",
    "- Calculation of posterior probabilities\n",
    "- Prediction of the most likely class for a new document\n",
    "\n",
    "This program shows how probabilistic models classify text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e332aebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Comedy | D) = 7.324218750000001e-05\n",
      "P(Action | D) = 0.00017146776406035664\n",
      "Predicted: action\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Training documents\n",
    "docs = [\n",
    "    (\"fun couple love love\".split(), \"comedy\"),\n",
    "    (\"fast furious shoot\".split(), \"action\"),\n",
    "    (\"couple fly fast fun fun\".split(), \"comedy\"),\n",
    "    (\"furious shoot shoot fun\".split(), \"action\"),\n",
    "    (\"fly fast shoot love\".split(), \"action\")\n",
    "]\n",
    "\n",
    "# Document to classify\n",
    "D = \"fast couple shoot fly\".split()\n",
    "\n",
    "# Classes\n",
    "classes = {\"comedy\", \"action\"}\n",
    "\n",
    "# ----- Priors -----\n",
    "priors = {}\n",
    "for c in classes:\n",
    "    count = sum(1 for _, cls in docs if cls == c)\n",
    "    priors[c] = count / len(docs)\n",
    "\n",
    "# ----- Vocabulary -----\n",
    "vocab = set()\n",
    "for words, _ in docs:\n",
    "    for w in words:\n",
    "        vocab.add(w)\n",
    "\n",
    "V = len(vocab)\n",
    "\n",
    "# ----- Word counts & total words per class -----\n",
    "wc = {c: Counter() for c in classes}\n",
    "tw = {c: 0 for c in classes}\n",
    "\n",
    "for words, c in docs:\n",
    "    wc[c].update(words)\n",
    "    tw[c] += len(words)\n",
    "\n",
    "# ----- Posterior probability -----\n",
    "def class_probability(c):\n",
    "    prob = priors[c]\n",
    "    for w in D:\n",
    "        word_prob = (wc[c][w] + 1) / (tw[c] + V)\n",
    "        prob *= word_prob\n",
    "    return prob\n",
    "\n",
    "p_comedy = class_probability(\"comedy\")\n",
    "p_action = class_probability(\"action\")\n",
    "\n",
    "print(\"P(Comedy | D) =\", p_comedy)\n",
    "print(\"P(Action | D) =\", p_action)\n",
    "\n",
    "# Prediction\n",
    "prediction = \"action\" if p_action > p_comedy else \"comedy\"\n",
    "print(\"Predicted:\", prediction)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
