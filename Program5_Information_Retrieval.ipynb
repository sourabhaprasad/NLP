{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddb23703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Brown categories: ['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery']\n",
      "Brown sample words: ['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced']\n",
      "Brown sample sentence: ['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.']\n",
      "\n",
      "Inaugural files: ['1789-Washington.txt', '1793-Washington.txt', '1797-Adams.txt']\n",
      "Inaugural 2009 sample: ['My', 'fellow', 'citizens', ':', 'I', 'stand', 'here', 'today', 'humbled', 'by', 'the', 'task', 'before', 'us', ',']\n",
      "\n",
      "Reuters categories: ['acq', 'alum', 'barley', 'bop', 'carcass', 'castor-oil', 'cocoa', 'coconut']\n",
      "Reuters sample words: ['FRENCH', 'FREE', 'MARKET', 'CEREAL', 'EXPORT', 'BIDS', 'DETAILED', 'French', 'operators', 'have']\n",
      "\n",
      "UDHR languages: ['Abkhaz-Cyrillic+Abkh', 'Abkhaz-UTF8', 'Achehnese-Latin1', 'Achuar-Shiwiar-Latin1', 'Adja-UTF8']\n",
      "UDHR English sample: ['Universal', 'Declaration', 'of', 'Human', 'Rights', 'Preamble', 'Whereas', 'recognition', 'of', 'the', 'inherent', 'dignity']\n",
      "\n",
      "===== CUSTOM CORPUS =====\n",
      "Corpus files: ['sports/s1.txt', 'sports/sports1.txt', 'tech/t1.txt', 'tech/tech1.txt']\n",
      "\n",
      "Sports freq: [('the', 4), ('.', 4), ('team', 2), ('won', 2), ('match', 2)]\n",
      "Tech freq: [('artificial', 2), ('intelligence', 2), ('innovation', 2), ('.', 2), ('drives', 1)]\n",
      "\n",
      "===== TAGGED CORPUS =====\n",
      "Tagged words: [('The', 'DT'), ('team', 'NN'), ('won', 'VBD'), ('the', 'DT'), ('match', 'NN'), ('.', '.'), ('Players', 'NNS'), ('performed', 'VBD'), ('well', 'RB'), ('.', '.'), ('The', 'DT'), ('team', 'NN'), ('won', 'VBD'), ('the', 'DT'), ('match', 'NN'), ('.', '.'), ('Players', 'NNS'), ('performed', 'VBD'), ('well', 'RB'), ('.', '.'), ('Artificial', 'JJ'), ('intelligence', 'NN'), ('drives', 'NNS'), ('modern', 'JJ'), ('innovation', 'NN'), ('.', '.'), ('Artificial', 'JJ'), ('intelligence', 'NN'), ('is', 'VBZ'), ('transforming', 'VBG')]\n",
      "Tagged sentence sample: [('The', 'DT'), ('team', 'NN'), ('won', 'VBD'), ('the', 'DT'), ('match', 'NN'), ('.', '.')]\n",
      "\n",
      "Most frequent nouns: [('NN', 7), ('NNS', 3)]\n",
      "\n",
      "===== TAGGERS =====\n",
      "Rule-based: [('This', 'NN'), ('is', 'NN'), ('a', 'NN'), ('test', 'NN')]\n",
      "Unigram accuracy: 0.5\n",
      "Unigram tagging example: [('AI', 'NN'), ('is', 'NN'), ('changing', 'NN'), ('the', 'DT'), ('world', 'NN')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pb/n82bbfrs0nv8k11gz790ggdw0000gn/T/ipykernel_19198/1240105253.py:76: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  print(\"Unigram accuracy:\", unigram_tagger.evaluate(test_sents))\n"
     ]
    }
   ],
   "source": [
    "import nltk, ssl, os\n",
    "from nltk.corpus import brown, inaugural, reuters, udhr\n",
    "from nltk.probability import ConditionalFreqDist\n",
    "from nltk.tag import UnigramTagger\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "print(\"\\nBrown categories:\", brown.categories()[:10])\n",
    "print(\"Brown sample words:\", brown.words()[:15])\n",
    "print(\"Brown sample sentence:\", brown.sents()[0])\n",
    "\n",
    "print(\"\\nInaugural files:\", inaugural.fileids()[:3])\n",
    "print(\"Inaugural 2009 sample:\", inaugural.words('2009-Obama.txt')[:15])\n",
    "\n",
    "print(\"\\nReuters categories:\", reuters.categories()[:8])\n",
    "print(\"Reuters sample words:\", reuters.words('training/9865')[:10])\n",
    "\n",
    "print(\"\\nUDHR languages:\", udhr.fileids()[:5])\n",
    "print(\"UDHR English sample:\", udhr.words('English-Latin1')[:12])\n",
    "\n",
    "print(\"\\n===== CUSTOM CORPUS =====\")\n",
    "\n",
    "root = \"mycorpus\"\n",
    "os.makedirs(root + \"/sports\", exist_ok=True)\n",
    "os.makedirs(root + \"/tech\", exist_ok=True)\n",
    "\n",
    "with open(root + \"/sports/s1.txt\", \"w\") as f:\n",
    "    f.write(\"The team won the match. Players performed well.\")\n",
    "with open(root + \"/tech/t1.txt\", \"w\") as f:\n",
    "    f.write(\"Artificial intelligence drives modern innovation.\")\n",
    "\n",
    "tokenizer = WordPunctTokenizer()\n",
    "mycorpus = PlaintextCorpusReader(root, r\".*\\.txt\", word_tokenizer=tokenizer)\n",
    "\n",
    "print(\"Corpus files:\", mycorpus.fileids())\n",
    "\n",
    "# Conditional Frequency Distribution\n",
    "cfd = ConditionalFreqDist(\n",
    "    (file.split('/')[0], word.lower())\n",
    "    for file in mycorpus.fileids()\n",
    "    for word in mycorpus.words(file)\n",
    ")\n",
    "\n",
    "print(\"\\nSports freq:\", cfd[\"sports\"].most_common(5))\n",
    "print(\"Tech freq:\", cfd[\"tech\"].most_common(5))\n",
    "\n",
    "print(\"\\n===== TAGGED CORPUS =====\")\n",
    "\n",
    "sample = mycorpus.words()[:30]\n",
    "tagged_words = nltk.pos_tag(sample, lang=\"eng\")\n",
    "print(\"Tagged words:\", tagged_words)\n",
    "\n",
    "tagged_sents = [nltk.pos_tag(sent, lang=\"eng\") for sent in mycorpus.sents()]\n",
    "print(\"Tagged sentence sample:\", tagged_sents[0])\n",
    "\n",
    "# Most frequent noun tags\n",
    "noun_tags = [\"NN\", \"NNS\", \"NNP\", \"NNPS\"]\n",
    "noun_freq = nltk.FreqDist(tag for (_, tag) in tagged_words if tag in noun_tags)\n",
    "\n",
    "print(\"\\nMost frequent nouns:\", noun_freq.most_common())\n",
    "\n",
    "print(\"\\n===== TAGGERS =====\")\n",
    "\n",
    "# Rule-based Tagger\n",
    "default_tagger = nltk.DefaultTagger(\"NN\")\n",
    "print(\"Rule-based:\", default_tagger.tag([\"This\", \"is\", \"a\", \"test\"]))\n",
    "\n",
    "# Unigram Tagger\n",
    "train_size = int(len(tagged_sents) * 0.8)\n",
    "train_sents = tagged_sents[:train_size]\n",
    "test_sents = tagged_sents[train_size:]\n",
    "\n",
    "unigram_tagger = UnigramTagger(train_sents, backoff=default_tagger)\n",
    "\n",
    "if test_sents:\n",
    "    print(\"Unigram accuracy:\", unigram_tagger.evaluate(test_sents))\n",
    "\n",
    "print(\"Unigram tagging example:\",\n",
    "      unigram_tagger.tag(\"AI is changing the world\".split()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
