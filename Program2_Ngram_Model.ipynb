{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a22e9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence: 'I love learning'\n",
      "Unigram Probability:  0.0016904583020285497\n",
      "Bigram Probability :  0.3333333333333333\n",
      "Trigram Probability: 0.3333333333333333\n",
      "\n",
      "Sentence: 'language models learn'\n",
      "Unigram Probability:  0.00018782870022539445\n",
      "Bigram Probability :  0.5\n",
      "Trigram Probability: 1.0\n",
      "\n",
      "Sentence: 'learning models love'\n",
      "Unigram Probability:  0.0005634861006761833\n",
      "Bigram Probability :  0\n",
      "Trigram Probability: 0\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.probability import FreqDist, ConditionalFreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# nltk.download('punkt_tab')\n",
    "\n",
    "text = \"\"\"\n",
    "I love natural language processing.\n",
    "I love machine learning.\n",
    "Language models learn patterns.\n",
    "I love learning new things.\n",
    "\"\"\"\n",
    "\n",
    "tokens = word_tokenize(text.lower())\n",
    "\n",
    "unigrams = FreqDist(tokens)\n",
    "bigrams = ConditionalFreqDist(ngrams(tokens, 2))\n",
    "trigrams = ConditionalFreqDist(((a, b), c) for a, b, c in ngrams(tokens, 3))\n",
    "\n",
    "def unigram_prob(w):\n",
    "    return unigrams[w] / unigrams.N()\n",
    "\n",
    "def bigram_prob(w1, w2):\n",
    "    return bigrams[w1][w2] / bigrams[w1].N() if bigrams[w1][w2] else 0\n",
    "\n",
    "def trigram_prob(w1, w2, w3):\n",
    "    return trigrams[(w1, w2)][w3] / trigrams[(w1, w2)].N() if trigrams[(w1, w2)][w3] else 0\n",
    "\n",
    "def sentence_probability(sentence):\n",
    "    words = word_tokenize(sentence.lower())\n",
    "\n",
    "    uni = 1\n",
    "    for w in words:\n",
    "        uni *= unigram_prob(w)\n",
    "\n",
    "    bi = 1\n",
    "    for w1, w2 in ngrams(words, 2):\n",
    "        bi *= bigram_prob(w1, w2)\n",
    "\n",
    "    tri = 1\n",
    "    for w1, w2, w3 in ngrams(words, 3):\n",
    "        tri *= trigram_prob(w1, w2, w3)\n",
    "\n",
    "    return uni, bi, tri\n",
    "\n",
    "sentences = [\"I love learning\", \"language models learn\", \"learning models love\"]\n",
    "\n",
    "for s in sentences:\n",
    "    up, bp, tp = sentence_probability(s)\n",
    "    print(f\"\\nSentence: '{s}'\")\n",
    "    print(\"Unigram Probability: \", up)\n",
    "    print(\"Bigram Probability : \", bp)\n",
    "    print(\"Trigram Probability:\", tp)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
